from __future__ import annotations

import os
import sys
from pathlib import Path

from PIL import Image, ImageDraw

ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))

from core.pipeline import AvatarPipeline, PipelineInputs


def make_dummy_avatar(path: Path) -> Path:
    size = 512
    img = Image.new("RGB", (size, size), (12, 16, 24))
    draw = ImageDraw.Draw(img)
    draw.ellipse((140, 120, 372, 360), fill=(52, 94, 200))
    draw.text((160, 380), "RealTalk Demo", fill=(220, 230, 255))
    img.save(path)
    return path


def make_dummy_voice(path: Path) -> Path:
    # Not used in dummy mode, but required by the pipeline signature
    path.write_bytes(b"dummy")
    return path


def main() -> None:
    os.environ["CODEXOFFLINEVIDEO_DUMMY"] = "1"

    output_dir = Path("outputs") / "dummy_test"
    output_dir.mkdir(parents=True, exist_ok=True)

    avatar_path = make_dummy_avatar(output_dir / "avatar.png")
    voice_path = make_dummy_voice(output_dir / "voice.wav")

    script = (
        "Hello! This is a short demo script generated by ChatGPT for an end-to-end test. "
        "We are verifying the pipeline and GUI flow with a placeholder render."
    )

    pipeline = AvatarPipeline()
    outputs = pipeline.run(
        PipelineInputs(
            avatar_image=avatar_path,
            script_text=script,
            voice_sample=voice_path,
            reference_video=None,
        )
    )

    print("E2E dummy render complete:", outputs.video_path)


if __name__ == "__main__":
    main()
